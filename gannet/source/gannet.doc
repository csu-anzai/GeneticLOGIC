GANNET.doc                        VERSION .91                   5 Sept 1990

----------------------------------------------------------------------------
|           *****      *      *     *   *     *  ******  *******           |
|          *          * *     * *   *   * *   *  *          *              |
|          *   **    *   *    *  *  *   *  *  *  *****      *              |
|          *    *   *******   *   * *   *   * *  *          *              |
|           *****   *     *   *     *   *     *  ******     *              |
----------------------------------------------------------------------------

Purpose:
-------

      GANNET (Genetic Algorithm Neural NETwork) is an experimental
program designed to evolve neural networks to solve pattern
recognition problems. This document explains how the program is put
together and how it should be used.  GANNET can be adapted to solve
other types of problems.  Neural networks are evolved using a genetic
algorithm.

For further information contact:
	    Professor Kenneth J. Hintz
	    Department of Electrical and Computer Engineering
	    George Mason University
	    4400 University Drive
	    Fairax, VA 22030

	    email:  khintz@gmuvax2.gmu.edu
	    tel:    (703)993-1592

Written by: Captain Jason J. Spofford, USAF
	    ECE Graduate Student, George Mason University

Copyright (C) 1990  Jason J. Spofford

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 1, or any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

A copy of the GNU General Public License is included in this document;
if not, write to the Free Software Foundation, Inc., 675 Mass Ave,
Cambridge, MA 02139, USA.

Organization:
------------

	GANNET is written in ANSI C and has been compiled successfully
on SUN and VAX platforms operating under UNIX.  The program consists
of 13 files.  These are:

Makefile - contains compiling instructions for creating the GANNET
executable. On a UNIX platform, type 'make -k' to compile.

comdef.h - contains common definitions of variable types and constants.

GANNET.c - This is the largest source file containing most of the
GA process and the main function.

parinfo.c - works with the parent information file called
"par_info.experiment." The parent information file contains a parent's fitness,
number of neurons, etc... and is stored in binary format.

gen_code.c - works with genetic code information.  The genetic
code is stored in binary format.  The parent information array
contains seek pointers that indicate where one individuals code stops
and another begins.

statistic.c - records statistical information about the evolution
process and stores it in a flat ASCII format that can be imported into
spreadsheets. The format may have to be modified to work with
different spreadsheet import facilities.

history.c - records the history of the evolution process in an ASCII
file called history.extension.  This file can be useful for
determining how long a particular job took, for debugging information
and for determining the number of times an experiment was conducted.

graycode.c - contains routines for converting integers to and from
the graycode scheme.

best.c - records the best phenotype created at particular generation
intervals. The file, best.experiment, is in ASCII format.

config.c - loads and saves the configuration information for each
experiment.

io_load.c - loads input/ output evaluation data.

combo4.data - an ASCII data file that contains specific sets of
weights and thresholds that translate into produceable neuron output
combinations for a 4 input neuron. This information is loaded into a
large array at the startup of GANNET.

combo2.data.full - an ASCII data file that contains specific sets of
weights and thresholds that translate into produceable neuron output
combinations for a 2 input neuron. This information is loaded into a
large array at the startup of GANNET.

GANNET's Experiment Files:
-------------------------

GANNET creates several experiment files and it is important to
understand what each file represents. The experiment name is used as
an extension.  In the DOS environment, it might make more sense to
reverse that, using the type of file as the extension.

The following files are created by GANNET:

best.experiment - This ASCII data file contains the best phenotype of
a particular generation. There is enough information in this file to
plot a given neural network. Important statistic information about the
neural network is recorded first. After which, the phenotype is
expressed.  
	The phenotype values must be understood before an accurate
neural network can be constructed. Each row represents a neuron.  The
first number uniquely identifies a neuron.  The next number is the
threshold level. The next 4 numbers are the input weights to that
neuron, starting at 1 and ending at 4.  The last four numbers
represent where that neuron is receiving its inputs from, again, 1
through 4.  A neuron can receive input from another neuron or from the
environment. If the number is less than the number of environmental
inputs, that neuron is connected to an environmental input. Use the
number as it appears.  If the number is greater than or equal to the
number of environmental inputs, subtract off the number of
environmental inputs and you are left with the neuron number its
receives input from.  For a two input neuron model, ignore weights and
connections 3 and 4.  Also, there is an additional number tacked on
the end of the row. This is the second threshold value for this
different neuron model.

input.experiment - This file contains input patterns for neural
networks to recognize. Never make any comments containing a 1 or a 0,
or it will be interpreted as data. The loader ignores everything
except 1's and 0's so you are free to arrange your input data however
you please. At the top of the file, you should indicate how many
input/ output sets there are and how many environmental inputs there
are. This is not required, however.

output.experiment - The same things that hold true for
input.experiment hold true for this file.  This file tells the GA what
patterns the neural network should recognize as being the same, and
what should be recognized distinctly.

par_info.experiment - The parent information for each parent in the
population is stored in this binary file. Information such as
fitness, number of neurons, age, etc... is stored here.

par_code.experiment - Parent genetic code is stored here. The parent
information file contains seek pointers for identifying where genetic
code strings start and stop.

stats.experiment - A summary of statistics per generation is recorded
in ASCII format.  Each line in the file contains a description of a
generation. Each value in a statistics file is separated with a single
space.

Here is a brief description of the statistics recorded for each generation:

Field
-----
 1      The generation number.
 2      The number of times a parent replaces one of its children.
 3      % of parents assigned ZERO reproductive allocations.
 4      Fitness of the best overall parent.
 5      Average overall fitness of the parent population.
 6      Fitness of the worst overall parent.
 7      Fitness of the best input/output performing parent.
 8      Average input/output fitness of the parent population.
 9      Fitness of the worst input/output performing parent.
10      Fitness of the best cycle time performing parent.
11      Average cycle time fitness of the parent population.
12      Fitness of the worst cycle time performing parent.
13      Fitness of the smallest neural network size parent.
14      Average neural network size fitness of the parent population.
15      Fitness of the largest neural network size parent.
16      Number of neurons in the largest network.
17      Average number of neurons in the parent population.
18      Number of neurons in the smallest network.

	When networks use there own featural representation of input stimuli,
	these fields measure how different one representation is from other
	representations. (when they are supposed to be different)

19      The largest difference score.
20      The average difference score.
21      The smallest difference score.

	Now instead of measuring the difference of featural representations,
	these fields measure how similar featural representations are when
	neural networks are given input stimuli that should be mapped to the
	same representation.

22      The largest similarity score.
23      The average similarity score.
24      The smallest similarity score.

	Finally, a long list provides the number of times, in the entire
	parent population, a particular neuron is used as an output
	neuron.  Fitness is measured from the output neurons.

25      The neuron number.
26      The number of times it is used as an output neuron.

27      Continued for all neuron numbers ...
28      ... 


conf.experiment - This configuration file contains the parameters of
the experiment.  Here are some notes on the various fields. This file
is stored in ASCII.

Experiment      - The experiment name.

Population Size - The number of individuals in a population per
generation.  The population size must always be an even number.

Max Generations - The maximum number of generations you would like the
experiment to run.  Note, you can restart an experiment after it is
done. If you indicate 0, the experiment will continue until fitness
reaches a certain "Minimum Fitness."

Curr Generation - When starting an experiment, the current generation field
should be one. If you are continuing the experiment, this number will
automatically be maintained so all generation numbers remain unique.

Random Seed 1 - This is the random seed value given prior to creating the
initial random population. 

Random Seed 2 - This is the random seed for the evolution process itself.

Max # of Neurons - This is the maximum number of neurons per net EVER
allowed in the experiment.  Memory is allocated based on this value so
don't make it too large.

Mean # of Neurons - This number represents what the mean number of neurons
should be in the initial, randomly generated, population.

+/- Deviation - This value provides a uniform spread of neural network
sizes from the given Mean # of Neurons. If its value is zero, all
networks will have the same number of neurons.

Environ. Outputs - Every neural network has a certain number of outputs. These
outputs are used to determine a NN's fitness. If you change this value, be sure
to change the number of output bits in the output.experiment file.

Environ. Inputs - This field represents the number of environmental
inputs to each NN. If you should change this number, than adjust
input.experiment accordingly. All inputs are binary, 1 or 0. GANNET
will translate all zero entries to -1 before presenting data to the
NNs for evaluation.

# of I/O Sets - For every input, there is an output. This parameter
indicates how many input/output sets there are. If you want a NN to
recognize the alphabet, than the number should be 26. Be sure to have
the correct number of entries in the input and output experiment files. 

Stats Interval - For long experiments, you may not want to record
statistics every generation. Statistics will be recorded every Stats
Interval number of generations. Minimum value is 1.

Best Net Interval - You may not want to record the best phenotype for
every generation. Depending on the number of neurons, this file can
grow quickly. The best net will be recorded every Best Net Interval
number of generations. Minimum value is 1.

Maximum Age - A parent can replace one of its children if it is better
in fitness then the child. If you indicate an age of 1, the parent
will never replace its child. If you indicate an age of 0, a parent
will survive as long as it is better in fitness than its child. If you
pick a number greater than one, than the parent will continue to exist
for that number of generations, as long as it continues to be better
fit than its children.

Top Heavy - This parameter can be set to 1 or 0 only. If it is set to
1, then the best fit parent to date will get special treatment. The
first time a parent reaches the best fitness for the entire
population, it will replace its less fit children.  This parameter has
less of an affect than Maximum Age but still serves to bias the
population towards the best performers.

Neuron Model - Since GANNET only allows each neuron to have a fixed
number of inputs, this parameter allows you to pick either a 2 input
neuron model or a 4 input neuron model. Don't indicate any other
values, I assure you, it won't work.

Biased Model - The output combinations generatable by a neuron turn
out to be biased, if one chooses weights and thresholds uniformly.
If this parameter is set to 1, a bias is ensured. If set to 0,
each output combination will have an equal chance of occurring.

Clear Net State - Before any inputs are presented to a NN, the NN is
set to a special dead state. Each output of every neuron is set to 0.
If you don't want to do that, set the Clear Net State parameter to 0.
If you don't clear the state, the NN's may generate solutions that are
based on internal memory rather than the inputs.

Net Free Repr. - The Network Free Representation parameter is not easy
to describe. If it is set to 0, for every input pattern presented to a
NN, the NN will have to generate an output binary pattern exactly
matching the pattern described in the output.experiment file.  If it
is set to 1, the NN can choose whatever representations it naturally
falls into.  If the output.experiment file indicates two input patterns
should be mapped to the same output, points are awarded based on how
similar the two output values actually are. If two input patterns are
supposed to be different, points are awarded based on how many other
output values they are different from.

Normal Crossover - Two crossover models are provided. If normal
crossover is set to 1, than for every generation, a random number of
crossover points are selected at random locations. If set to 0,
crossover locations are actually part of the genetic code. In the
initial population, crossover locations are selected randomly. After
which, crossover locations are subjected to the genetic algorithm.
This second method was borrowed from J. David Schaffer's "An Adaptive
Crossover Distribution Mechanism for Genetic Algorithms," in the
Second International Conference on Genetic Algorithms, July 1987.

Mutate Bit - Two types of mutation operators are provided. If Mutate
Bit is set to 1, than every bit in the genetic code is subjected to
mutation, one bit at a time. If set to 0, a whole parameter is mutated
at once (uniformly), whether it be a behavior, output selector, or
connection.

Fixed Outputs - If Fixed Outputs is set to 1, than every NN ignores
the output selector genetic code. Instead, outputs are fixed at
certain neuron locations. If set to 0, outputs are chosen by
the genetic algorithm.

Fitness Scale - This field controls the number of children each parent
gets to participate in.  A parent can participate in creating 0, 2 or
4 children.  The parameter can vary from 0 to 1. The higher the value,
the more parents participate in creating four children and the more
parents that have no children. The higher fitness a parent has, the
greater chance a parent has to be selected to participate in having
four children.  This process was borrowed from James Edward Baker's
paper entitled, "Reducing Bias and Inefficiency in the Selection
Algorithm," in the Second International Conference on Genetic
Algorithms, July 1987.  Formally, it is called "Stochastic Universal
Sampling."

Stable Test Time - For pattern recognition, we need to know when the
output results have stabilized. The Stable Test Time parameter is how
long we look at the outputs to see if they are actually stable. If an
output value changes during this period, it is considered unstable and
counts against the fitness of the NN. The Stable Test Time is scaled
to the size of the NN in question. A Stable Test Time of .5 and a NN
with 26 neurons would be tested for stability for 13 cycles.

Conver. Test Time - Each NN must be given a certain amount of time to
solve a problem.  The Convergence Test Time parameter is scaled to the
size of the NN in question.  A value of 1.0 will give a NN with 26
neurons, 26 cycles to converge to a solution.  It is possible to
detect convergence before that time, but some NN's have some unstable
portions which are never expressed in the output.

Input/ Output - The Input/ Output parameter is used to calculate overall
fitness. This value is multiplied times the Input/ Output fitness
calculation and added with the two other fitness measurement to
determine overall fitness. If the value is 1, that means the Input/
Output performance is the only important consideration in your
experiment.

Reduce Neuron - The Reduce Neuron parameter is used to calculate
overall fitness. If you want to penalize a NN for having too many
neurons, make this value non-zero.

Reduce Cycles - If the time to calculate a solution is important, make
the Reduce Cycles parameter non-zero. Remember, Reduce Cycle + Reduce
Neuron + Input/ Output must always add to 1.0.

Minimum Fitness - If you indicated a 0 for Maximum Generations, when
the best fit NN reaches Minimum Fitness, the experiment will stop.
This parameter is used only if Maximum Generations is 0.
 
Crossover Rate - This is the probability each bit will be a crossover
site. This term must never equal zero! The lowest allowable value is
0.000001!  When not using Normal Crossover, than this rate is used to
generate the initial crossover points in the population.

Behavior Mutation - This is the probability of mutation per bit of the
genetic code reprepresenting a neuron's behavior (its weights and
threshold). This term must never equal zero!

Output Mutation - The probability of a bit mutation in the output
selector genetic code. This term must never equal zero!

Connect Mutation - The probability of a bit mutation in the
connections between neurons as expressed in the genetic code. This
term must never equal zero!

Cross Mutation - If genetic crossover is used, this is the probability
of a bit mutation of the crossover genetic code. This term must never
equal zero!

Sim/Dif Strength - The Similarity / Difference Strength is used if a
free network representation is used.  Since points are scored based on
similarity and differences, the relative importance of similarity
points and difference points must be established. The lower the number,
the more important difference points are.

Prob of Resize - This is another mutation operator that attempts to
either insert or delete a neuron from a NN. It represents the
probability that a child will be subjected to a resize attempt.

Input Noise - This parameter represents the % chance a input data bit
will be flipped.  It is meant to be used in evolving NNs that require
high noise immunity.  Every generation is subjected to the same noisy
data.  Not much experimentation has been conducted with this variable.

Using GANNET:
-------------

	Now that the program and its files have been explained to some
extent, and assuming you were able to get it compiled, this section
will tell you how to GANNET. 
	
	First determine what type of problem you'd like to solve and
create the required the input and output files using a text editor.
Be sure not to include any 0's or 1's in any comments you make.

	Second, be sure combo4.data and combo2.data are in the same
directory as GANNET.  Once this is completed, type "GANNET {exper.name}"
and hit return.  GANNET will first try to find a configuration
file for that experiment. If one doesn't exist, it will proceed to ask
you to enter in configuration information. Be sure to enter
only a few generations for Maximum Generations. Most likely you will
want to run GANNET in the background. After your initial Evolve
experiment completes, edit the conf.{exper. name} file, increasing the
Maximum Generations to the length you really want. Then type "GANNET
{exper.  name} &" and hit return. Now GANNET is running in the
background.

	If you run GANNET, and it asks you to check the history file,
it means for some reason the program couldn't run properly. By reading
the history file, the reason should hopefully become apparent. Correct
the problem and try again.  Remember, all the experiment files must be
in the same directory as GANNET.

	There are several parameters to vary, experiment to
experiment. Play around with these values on a small experiment to get
a feel for the program. This program is not without bugs - hopefully
most of them are already taken care of. If you find one, let me know
and I will try to fix it or better yet, fix it yourself and send me an
update. Good Luck!


========================================================================
		    GNU GENERAL PUBLIC LICENSE
		     Version 1, February 1989

 Copyright (C) 1989 Free Software Foundation, Inc.
		    675 Mass Ave, Cambridge, MA 02139, USA
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

			    Preamble

  The license agreements of most software companies try to keep users
at the mercy of those companies.  By contrast, our General Public
License is intended to guarantee your freedom to share and change free
software--to make sure the software is free for all its users.  The
General Public License applies to the Free Software Foundation's
software and to any other program whose authors commit to using it.
You can use it for your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Specifically, the General Public License is designed to make
sure that you have the freedom to give away or sell copies of free
software, that you receive source code or can get it if you want it,
that you can change the software or use pieces of it in new free
programs; and that you know you can do these things.

  To protect your rights, we need to make restrictions that forbid
anyone to deny you these rights or to ask you to surrender the rights.
These restrictions translate to certain responsibilities for you if you
distribute copies of the software, or if you modify it.

  For example, if you distribute copies of a such a program, whether
gratis or for a fee, you must give the recipients all the rights that
you have.  You must make sure that they, too, receive or can get the
source code.  And you must tell them their rights.

  We protect your rights with two steps: (1) copyright the software, and
(2) offer you this license which gives you legal permission to copy,
distribute and/or modify the software.

  Also, for each author's protection and ours, we want to make certain
that everyone understands that there is no warranty for this free
software.  If the software is modified by someone else and passed on, we
want its recipients to know that what they have is not the original, so
that any problems introduced by others will not reflect on the original
authors' reputations.

  The precise terms and conditions for copying, distribution and
modification follow.

		    GNU GENERAL PUBLIC LICENSE
   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION

  0. This License Agreement applies to any program or other work which
contains a notice placed by the copyright holder saying it may be
distributed under the terms of this General Public License.  The
"Program", below, refers to any such program or work, and a "work based
on the Program" means either the Program or any work containing the
Program or a portion of it, either verbatim or with modifications.  Each
licensee is addressed as "you".

  1. You may copy and distribute verbatim copies of the Program's source
code as you receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice and
disclaimer of warranty; keep intact all the notices that refer to this
General Public License and to the absence of any warranty; and give any
other recipients of the Program a copy of this General Public License
along with the Program.  You may charge a fee for the physical act of
transferring a copy.

  2. You may modify your copy or copies of the Program or any portion of
it, and copy and distribute such modifications under the terms of Paragraph
1 above, provided that you also do the following:

    a) cause the modified files to carry prominent notices stating that
    you changed the files and the date of any change; and

    b) cause the whole of any work that you distribute or publish, that
    in whole or in part contains the Program or any part thereof, either
    with or without modifications, to be licensed at no charge to all
    third parties under the terms of this General Public License (except
    that you may choose to grant warranty protection to some or all
    third parties, at your option).

    c) If the modified program normally reads commands interactively when
    run, you must cause it, when started running for such interactive use
    in the simplest and most usual way, to print or display an
    announcement including an appropriate copyright notice and a notice
    that there is no warranty (or else, saying that you provide a
    warranty) and that users may redistribute the program under these
    conditions, and telling the user how to view a copy of this General
    Public License.

    d) You may charge a fee for the physical act of transferring a
    copy, and you may at your option offer warranty protection in
    exchange for a fee.

Mere aggregation of another independent work with the Program (or its
derivative) on a volume of a storage or distribution medium does not bring
the other work under the scope of these terms.

  3. You may copy and distribute the Program (or a portion or derivative of
it, under Paragraph 2) in object code or executable form under the terms of
Paragraphs 1 and 2 above provided that you also do one of the following:

    a) accompany it with the complete corresponding machine-readable
    source code, which must be distributed under the terms of
    Paragraphs 1 and 2 above; or,

    b) accompany it with a written offer, valid for at least three
    years, to give any third party free (except for a nominal charge
    for the cost of distribution) a complete machine-readable copy of the
    corresponding source code, to be distributed under the terms of
    Paragraphs 1 and 2 above; or,

    c) accompany it with the information you received as to where the
    corresponding source code may be obtained.  (This alternative is
    allowed only for noncommercial distribution and only if you
    received the program in object code or executable form alone.)

Source code for a work means the preferred form of the work for making
modifications to it.  For an executable file, complete source code means
all the source code for all modules it contains; but, as a special
exception, it need not include source code for modules which are standard
libraries that accompany the operating system on which the executable
file runs, or for standard header files or definitions files that
accompany that operating system.

  4. You may not copy, modify, sublicense, distribute or transfer the
Program except as expressly provided under this General Public License.
Any attempt otherwise to copy, modify, sublicense, distribute or transfer
the Program is void, and will automatically terminate your rights to use
the Program under this License.  However, parties who have received
copies, or rights to use copies, from you under this General Public
License will not have their licenses terminated so long as such parties
remain in full compliance.

  5. By copying, distributing or modifying the Program (or any work based
on the Program) you indicate your acceptance of this license to do so,
and all its terms and conditions.

  6. Each time you redistribute the Program (or any work based on the
Program), the recipient automatically receives a license from the original
licensor to copy, distribute or modify the Program subject to these
terms and conditions.  You may not impose any further restrictions on the
recipients' exercise of the rights granted herein.

  7. The Free Software Foundation may publish revised and/or new versions
of the General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

Each version is given a distinguishing version number.  If the Program
specifies a version number of the license which applies to it and "any
later version", you have the option of following the terms and conditions
either of that version or of any later version published by the Free
Software Foundation.  If the Program does not specify a version number of
the license, you may choose any version ever published by the Free Software
Foundation.

  8. If you wish to incorporate parts of the Program into other free
programs whose distribution conditions are different, write to the author
to ask for permission.  For software which is copyrighted by the Free
Software Foundation, write to the Free Software Foundation; we sometimes
make exceptions for this.  Our decision will be guided by the two goals
of preserving the free status of all derivatives of our free software and
of promoting the sharing and reuse of software generally.

			    NO WARRANTY

  9. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
REPAIR OR CORRECTION.

  10. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
POSSIBILITY OF SUCH DAMAGES.

		     END OF TERMS AND CONDITIONS
